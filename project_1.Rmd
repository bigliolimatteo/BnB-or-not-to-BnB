---
title: "Airbnb Analysis"
author: "Matteo Biglioli"
date: "07/06/2021"
output:
  #pdf_document: default
  html_document: default
header-includes:
- \usepackage{subfig}
- \usepackage{bbm}
urlcolor: blue
abstract: |
  This paper will present a complete statistical analysis of Airbnb data from six major european cities. We start by presenting an exploratory analysis of our dataset, in which we try to identify both the most relevant components that drive prices and possible differences between the collected cities. We then evaluate different statistical learning models that predict the prices given different instrumental variables. At the end we generate different clusters both from the whole dataset and from subset related to single cities, to better understand the composition of the dataset.
  We find that
---
# 1. Introduction

Airbnb is an American company that operates an online marketplace for lodging, primarily homestays for vacation rentals, and tourism activities. It was born in 2007 and, since then, it has grown to 4 million Hosts who have welcomed more than 900 million guest arrivals in almost every country across the globe.
The app works as most of the other bookings apps: a client can just select a city he/she want to visit, the dates of the trip and a he/she will get a list of possible locations. The main difference that makes Airbnb unique in its kind is that in the website you can find not only hotels and apartments, but also single rooms that are rented out for a few days from private Hosts.
In this kind of environment Hosts are pushed to compete in an almost-free market, where they have to set the right price for their properties in order to stay competitive and win guests over.
We can assume that a good percentage of private Hosts has no experience in both Marketing and Real-Estate, hence the definition of the right price could become a entry barrier that stops most of them from ever trying to compete.

Our goal in this paper will be to understand which are the components that drive prices and to construct a model that can help both Hosts to define the right price for their properties and Guests to check weather a location could be a scam.


```{r echo=FALSE, message=FALSE, include=FALSE}
## Global vars
CITIES = c('London', 'Berlin', 'Roma', 'Barcelona', 'Amsterdam', 'Wien')

API_URL = 'https://data.opendatasoft.com/explore/dataset/airbnb-listings@public/download/?format=csv&disjunctive.host_verifications=true&disjunctive.amenities=true&disjunctive.features=true&refine.city=%s&timezone=Europe/Berlin&lang=en&use_labels_for_header=true&csv_separator=%%3B'

MAX_DOWNLOADED_ROWS_PER_CITY = c(5000)
MAX_ANALISED_ROWS_PER_CITY = c(5000)

DATASET_COLUMNS = c("ID","Name","Experiences.Offered","Host.Since","Host.Response.Time","Host.Response.Rate","City","Latitude","Longitude","Property.Type","Room.Type","Accommodates","Bathrooms","Bedrooms","Beds","Bed.Type","Amenities","Price","Security.Deposit","Cleaning.Fee","Minimum.Nights","Number.of.Reviews","Review.Scores.Rating","Review.Scores.Accuracy","Review.Scores.Cleanliness","Review.Scores.Checkin","Review.Scores.Communication","Review.Scores.Location","Review.Scores.Value","Cancellation.Policy","Features")
```



```{r, include=FALSE}
# TODO DEBUG - Remove in final paper
# Subselect column after download -> TODO remove
#for (city in CITIES) {
#    tmp_df = read.csv(glue::glue("data/airbnb/{city}.csv"))
#    write.csv(tmp_df %>% select(DATASET_COLUMNS), glue::glue("data/airbnb/{city}.csv"), row.names=FALSE)
#}
```

```{r, include=FALSE, message=FALSE,echo=FALSE}

# Install libraries
if(!require('pacman'))install.packages('pacman')
pacman::p_load(summarytools, glue,dplyr,plotly,leaflet,crosstalk,GoodmanKruskal,Hmisc,corrplot,geodist,factoextra,gridExtra)

# Load libraries
library(glue)
library(dplyr)
library(plotly)
library(leaflet)
library(crosstalk)
library(GoodmanKruskal)
library(Hmisc)
library(corrplot)
library(geodist)
library(factoextra)
library(summarytools)
library(gridExtra)

# Set the current directory as working directory and load custom functions.
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
```

```{r, include=FALSE, message=FALSE,echo=FALSE}

# Create data dir if not exists
dir.create(file.path(getwd(), 'data'), showWarnings = FALSE)
dir.create(file.path(paste0(getwd(), '/data'), 'airbnb'), showWarnings = FALSE)

# Download data if they are not present
for (city in CITIES){
  if (!file.exists(glue::glue("data/airbnb/{city}.csv"))){
    print(glue::glue("Downloading {city}"))
    tmp_df = read.csv(sprintf(API_URL, city), sep=';', nrows=MAX_DOWNLOADED_ROWS_PER_CITY)
    write.csv(tmp_df %>% select(DATASET_COLUMNS), glue::glue("data/airbnb/{city}.csv"), row.names=FALSE)
  }
  print(glue::glue("{city} imported."))
}
# Clean temporary variables
rm(tmp_df)
```

```{r, include=FALSE, message=FALSE,echo=FALSE}

# TODO DDEBUG - remove in final paper
if (FALSE){
  write.csv(df, 'debug.csv')
  df = read.csv('debug.csv')
    # Define column types
  df$Experiences.Offered  = factor(df$Experiences.Offered)
  df$Host.Response.Time   = factor(df$Host.Response.Time)
  df$City                 = factor(df$City)
  df$Property.Type        = factor(df$Property.Type)
  df$Room.Type            = factor(df$Room.Type)
  df$Bed.Type             = factor(df$Bed.Type)
  df$Cancellation.Policy  = factor(df$Cancellation.Policy)

} else {
  
  
## Load different cities and merge into full dataset
df_list = list()
for (i in seq_along(CITIES)) {
    df_list[[i]] = read.csv(glue::glue("data/airbnb/{CITIES[[i]]}.csv"), nrows=MAX_ANALISED_ROWS_PER_CITY)
}
df = data.table::rbindlist(df_list)
rm(df_list)


# TODO
## Compute Distance from City Center column
#center_london     = c(-0.109852, 51.510257)
#center_barcelona  = c(2.179218, 41.406116)
#center_roma       = c(12.490288, 41.897881)
#center_amsterdam  = c(4.895747, 52.375059)
#center_wien       = c(16.372340, 48.211068)
#center_berlin     = c(13.401755, 52.517132)
#
#df = df %>% rowwise() %>% mutate(
#     dist_from_city_center = case_when(
#         City == 'London'    ~ geodist(center_london, c(Longitude,Latitude)),
#         City == 'Barcelona' ~ geodist(center_barcelona, c(Longitude,Latitude)),
#         City == 'Roma'      ~ geodist(center_roma, c(Longitude,Latitude)),
#         City == 'Amsterdam' ~ geodist(center_amsterdam, c(Longitude,Latitude)),
#         City == 'Wien'      ~ geodist(center_wien, c(Longitude,Latitude)),
#         City == 'Berlin'    ~ geodist(center_wien, c(Longitude,Latitude))
#      )
#    ) %>% ungroup()
     

## Split columns with list of feature
df =  df %>% mutate(Host.ProfilePic  = grepl('Host Has Profile Pic',   df$Features),
                    Host.SuperHost   = grepl('Host Is Superhost',      df$Features),
                    Host.verified    = grepl('Host Identity Verified', df$Features),
                    Instant_Bookable = grepl('Instant Bookable',       df$Features),
                    Kitchen          = grepl('Kitchen',                df$Amenities),
                    Washer           = grepl('Washer',                 df$Amenities),
                    Breakfast        = grepl('Breakfast',              df$Amenities),
                    Air_conditioning = grepl('Air conditioning',       df$Amenities),
                   ) %>%  select(-Features, -Amenities)


## Define zero where no Cleaning Fee or Security Desposit is required
## Redefine Host.Since as a column we can work with
df =  df %>% mutate(Security.Deposit = coalesce(Security.Deposit, 0),
                    Cleaning.Fee     = coalesce(Cleaning.Fee, 0),
                    Host.Since       = as.integer(Sys.Date() - as.Date(Host.Since, format = "%Y-%m-%d"))
                  ) 


## Drop Nas and select only airbnbs with at least 10 reviews
df =  df %>% tidyr::drop_na() %>% filter(Number.of.Reviews > 10)


## Define column types
df$Experiences.Offered  = factor(df$Experiences.Offered)
df$Host.Response.Time   = factor(df$Host.Response.Time)
df$City                 = factor(df$City)
df$Property.Type        = factor(df$Property.Type)
df$Room.Type            = factor(df$Room.Type)
df$Bed.Type             = factor(df$Bed.Type)
df$Cancellation.Policy  = factor(df$Cancellation.Policy)
}
```

# 2. Data

```{r, include=FALSE}
# Define column groups
df_columns = colnames(df)
host_columns    = df_columns[grepl('Host', df_columns)]
review_columns  = df_columns[grepl('Review', df_columns)]
price_columns   = c('Price', 'Security.Deposit', 'Cleaning.Fee')
services_columns   = c('Instant_Bookable', 'Kitchen', 'Washer', 'Breakfast', 'Air_conditioning', 'Experiences.Offered', 'Cancellation.Policy')
accomodation_columns   = c('Property.Type', 'Room.Type', 'Accommodates', 'Bathrooms', 'Bedrooms', 'Beds', 'Bed.Type', 'Minimum.Nights')
```

We start our analysis by presenting our dataset. Before diving into the actual variables we present the six different cities and the related number of records:
```{r, echo=FALSE, fig.align = 'center'}
df_cities = df %>% count(City)
plot_ly(df_cities, type='pie', labels=~City, values=~n, textinfo='label+percent',insidetextorientation='radial')
```

For a better understanding we splitted the variables into five different groups that will be presented below.

#### 2.1 Host-related variables

These variables are related to features of the hosts, we have:

  * **Host.Since**: number of days since the Host is present on the platform.
  * **Host.Response.Time**: average response time of the Host.
  * **Host.Response.Rate**: average rate of responses of the Host.
  * **Host.ProfilePic**: weather the Host has a profile pic.
  * **Host.SuperHost**:  weather the Host is a SuperHost.
  * **Host.verified**:  weather the Host is verified.
```{r, echo=FALSE}
summary(df[, ..host_columns])
```

    
#### 2.2 Review-related variables

These variables are related to the different reviews, we have:

  * **Number.of.Reviews**: number of reviews of the property.
  * **Review.Scores.Rating**: overall rating (1-100).
  * **Review.Scores.Accuracy**: rating related to the accuracy of the host.
  * **Review.Scores.Cleanliness**: rating related to the cleanliness of the host.
  * **Review.Scores.Checkin**: rating related to checkin.
  * **Review.Scores.Communication**: rating related to the communication of the host.
  * **Review.Scores.Location**: rating related to the location.
  * **Review.Scores.Value**: overall rating (1-10).
```{r, echo=FALSE}
summary(df[, ..review_columns])
```


#### 2.3 Price-related variables

These variables are related to prices and fees, we have:

  * **Price**: price per night.
  * **Security.Deposit**: eventual security deposit (if NA, is set to 0).
  * **Cleaning.Fee**: eventual cleaning fee, una tantum (if NA, is set to 0).
```{r, echo=FALSE}
descr(df[, ..price_columns])
```

  
#### 2.4 Services-related variables

These variables are related to services included in booking, we have:

  * **Instant_Bookable**: weather a property is instantly bookable (without hosts' confirmation).
  * **Kitchen**: weather a kitchen is avaiable.
  * **Washer**: weather a washer is avaiable.
  * **Breakfast**: weather breakfast is included.
  * **Air_conditioning**:  weather air conditioning is avaiable.
  * **Experiences.Offered**:  kind of experience (romantic, business, ...).
  * **Cancellation.Policy**:  cancellation policy (fees, ...).
  * **Minimum.Nights**: minumin number of nights to spend at the property.
```{r, echo=FALSE}
summary(df[, ..services_columns])
```
  
    
#### 2.5 Accomodation-related variables

These variables are related to the actual location, we have:

  * **Property.Type**: type of the property.
  * **Room.Type**: type of the room.
  * **Accommodates**: number of people that can stay at the property.
  * **Bathrooms**: number of bathrooms.
  * **Bedrooms**:  number of bedrooms
  * **Beds**:  number of beds
  * **Bed.Type**:  type of the beds

```{r, echo=FALSE}
descr(df[, ..accomodation_columns])
```
# Data manipulation
# Todo use only rating overall?? maybe after showing relation w/ prices
The main goal of this analysis is to find what drive prices, the main issue we need to address is: **How do we define *Price*?**.
We oobserve that there are different variables related to prices and fees, that are:
 * Total price per night
 * Cleaning fee
 * Security deposit
For the scope of this paper we decide that we will define price as the per-person price of a seven-night stay at the property; we then compute 

```{r}
# Compute new price and remove useless columns
df = df %>% mutate(Price = (7*Price + Cleaning.Fee)/Accommodates) %>% select(-Cleaning.Fee)
```

# Exploratory analysis

We now present our dataset in a more sofisticated way, focusing on the relationships between the different variables that we collected and the prices.

We start by showing how prices differs in the different cities:
```{r, echo=FALSE}
# Aggregate data to do some plotting
agg_df = df %>% select(City, Latitude, Longitude, Price) %>%
                group_by(City) %>%
                summarise(across(everything(), list(mean))) %>%
                mutate(lat = Latitude_1, long = Longitude_1, price = Price_1) %>%
                select(City, lat, long, price)
```

```{r, echo=FALSE}
# Prepare palette
pal <- colorNumeric(
  palette = "viridis",
  domain = df$price)

# Prepare labels
labs <- lapply(seq(nrow(agg_df)), function(i) {
  paste0( '<p>', '<b>City:</b> ', agg_df[i, "City"][[1]], '<p></p>', 
          '<b>Avg Price - 7 nights:</b> ', round(agg_df[i, "price"], 2), '€</p>' ) 
})

# Construct map
m<-leaflet(agg_df) %>% addProviderTiles('CartoDB.Positron') %>% 
    addCircleMarkers(lng= ~long, lat= ~lat, color= ~pal(price), radius = ~price/10,
                     label = lapply(labs, htmltools::HTML), labelOptions = labelOptions(textsize = "15px")) %>%
    addLegend("bottomright", pal = pal, values = ~price, title = "Average price",
              labFormat = labelFormat(suffix = "€"), opacity = 1)

# Contruct boxplot
fig = plot_ly(df, y = ~Price, color = ~City, type = "box")

# Combine and show
p = bscols(m, fig)
p

```
We can see from the two graphs above that 4 out of the 6 cities are quite similar (Barcelona, Rome, Wien and Berlin), with an average 7-nights per-person price of about 160€. The two "outliers" are London, with a value of 220€ and Amsterdam, which unexpectedly shows a price of almost 350€.

Because we collected a sample dataset of less than 10k observations, we know that our analysis cannot assess that Amsterdam is overrall the most expensive city; that is because in the investigation above we do not control for other factors, such as accomodation and service features.

Proceeding with the order we used in the **Data** section, we will now try to assess if Host-related variables could be considered a driver for prices; to do so we plot the following:

```{r, echo=FALSE}
# TODO do this for all group of vars
#s1 = plot_ly(df, y = ~Price, x = ~Host.Since, type = "scatter", mode="markers")
#s2 = plot_ly(df, y = ~Price, x = ~Host.Response.Rate, type = "scatter", mode="markers")
#bscols(s1, s2)
#
#b1 = plot_ly(df, y = ~Price, color = ~Host.Response.Time, type = "box")
#b2 = plot_ly(df, y = ~Price, color = ~Host.ProfilePic, type = "box")
#b3 = plot_ly(df, y = ~Price, color = ~Host.SuperHost, type = "box")
#b4 = plot_ly(df, y = ~Price, color = ~Host.verified, type = "box")
#bscols(b1, b2, b3, b4)
#
#library("PerformanceAnalytics")
#chart.Correlation(as.matrix(df %>% dplyr::select(Price, Host.Since, Host.Response.Rate)), histogram=TRUE, pch=19)
#
#corr <- rcorr(as.matrix(df %>% dplyr::select(Price, Host.Since, Host.Response.Rate)))
#colnames(corr$r) <- c('Price', 'Host.Since', 'Host.Response.Rate')
#corrplot(corr$r, type = "upper", tl.col = "black", tl.srt = 45, tl.cex = .5)
```
# Correlation between variables
### Correlation plots
### Remove variables
#### Intuition/other
#### Subset selection
# Supervised learning
## Liner model
## Tree
# Unsupervised learning
## Hierarchical clustering
## Maybe kmeans w/ gower distance?
```{r}
#- show better stats/graphs on group of columns (as did above)
```
```{r, fig.height=2.5}
##- compute correlation matrix (qualitative and quantitative) to show what drives prices (and if it differs by city)
#quantitative_vars = c("Host.Since","Host.Response.Rate","Accommodates","Bathrooms","Bedrooms","Beds","Price","Security.Deposit","Cleaning.Fee","Number#.of.Reviews","Review.Scores.Rating","Review.Scores.Accuracy","Review.Scores.Cleanliness","Review.Scores.Checkin","Review.Scores.Communication","Review#.Scores.Location","Review.Scores.Value","dist_from_city_center")

#corr <- rcorr(as.matrix(df %>% dplyr::select(all_of(quantitative_vars))))
#colnames(corr$r) <- quantitative_vars
#corrplot(corr$r, type = "upper", tl.col = "black", tl.srt = 45, tl.cex = .5)
```
```{r, fig.height=4}
#- compute correlation matrix (qualitative and quantitative) to show what drives prices (and if it differs by city)
#qualitative_vars = c("Experiences.Offered","City","Property.Type","Room.Type","Bed.Type","Cancellation.Policy","Host.ProfilePic","Host.SuperHost","Hos#t.verified","Instant_Bookable","Kitchen","Washer","Breakfast","Air_conditioning")

#df$Host.ProfilePic  = factor(df$Host.ProfilePic)
#df$Host.SuperHost   = factor(df$Host.SuperHost)
#df$Host.verified    = factor(df$Host.verified)
#df$Instant_Bookable = factor(df$Instant_Bookable)
#df$Kitchen          = factor(df$Kitchen)
#df$Washer           = factor(df$Washer)
#df$Breakfast        = factor(df$Breakfast)
#df$Air_conditioning = factor(df$Air_conditioning)
#
#plot(GKtauDataframe(df %>% dplyr::select(all_of(qualitative_vars))))
```

```{r}
#plot_ly(df, y = ~Review.Scores.Rating, color = ~City, type = "box")
#plot_ly(df, y = ~Review.Scores.Accuracy, color = ~City, type = "box")
#plot_ly(df, y = ~Review.Scores.Cleanliness, color = ~City, type = "box")
#plot_ly(df, y = ~Review.Scores.Checkin, color = ~City, type = "box")
#plot_ly(df, y = ~Review.Scores.Communication, color = ~City, type = "box")
#plot_ly(df, y = ~Review.Scores.Location, color = ~City, type = "box")
#plot_ly(df, y = ~Review.Scores.Value, color = ~City, type = "box")
```

```{r}

# Define plots
#map_list = list()
#for (i in seq_along(CITIES)) {
#  
#  tmp_df = df %>% filter(City == CITIES[[i]], Price < 250) %>% sample_n(1000)
#
#    tmp_labs <- lapply(seq(nrow(tmp_df)), function(i) {
#    paste0( '<b>Avg Price per night:</b> ', round(tmp_df[i, "Price"], 2), '<br/>',
#            '<b>Dist from center:</b> ', round(tmp_df[i, "dist_from_city_center"], 2)) 
#  })
#
#  tmp_map <-leaflet(tmp_df) %>% addProviderTiles('CartoDB.Positron') %>% 
#    addCircleMarkers(lng= ~Longitude, lat= ~Latitude, color= ~pal(Price), radius=1, label = lapply(tmp_labs, htmltools::HTML)) %>%
#    addLegend(pal = pal, values = ~Price, title = "Average price",
#    labFormat = labelFormat(suffix = "€"))
#  
#  map_list[[i]] = tmp_map
#}
#
## Combine plots
#p1 = bscols(map_list[[1]], map_list[[2]])
#p2 = bscols(map_list[[3]], map_list[[4]])
#p3 = bscols(map_list[[5]], map_list[[6]])
#
## Show plots
#p1
#p2
#p3

```
```{r}
#- show better stats/graphs on group of columns (as did above)
#```
#```{r, fig.height=2.5}
##- compute correlation matrix (qualitative and quantitative) to show what drives prices (and if it differs by city)
#quantitative_vars = c("Host.Since","Host.Response.Rate","Accommodates","Bathrooms","Bedrooms","Beds","Price","Security.Deposit","Cleaning.Fee","Number#.of.Reviews","Review.Scores.Rating","Review.Scores.Accuracy","Review.Scores.Cleanliness","Review.Scores.Checkin","Review.Scores.Communication","Review#.Scores.Location","Review.Scores.Value","dist_from_city_center")
#
#corr <- rcorr(as.matrix(df %>% dplyr::select(all_of(quantitative_vars))))
#colnames(corr$r) <- quantitative_vars
#corrplot(corr$r, type = "upper", tl.col = "black", tl.srt = 45, tl.cex = .5)
#```
#```{r, fig.height=4}
##- compute correlation matrix (qualitative and quantitative) to show what drives prices (and if it differs by city)
#qualitative_vars = c("Experiences.Offered","City","Property.Type","Room.Type","Bed.Type","Cancellation.Policy","Host.ProfilePic","Host.SuperHost","Hos#t.verified","Instant_Bookable","Kitchen","Washer","Breakfast","Air_conditioning")
#
#df$Host.ProfilePic  = factor(df$Host.ProfilePic)
#df$Host.SuperHost   = factor(df$Host.SuperHost)
#df$Host.verified    = factor(df$Host.verified)
#df$Instant_Bookable = factor(df$Instant_Bookable)
#df$Kitchen          = factor(df$Kitchen)
#df$Washer           = factor(df$Washer)
#df$Breakfast        = factor(df$Breakfast)
#df$Air_conditioning = factor(df$Air_conditioning)
#
#plot(GKtauDataframe(df %>% dplyr::select(all_of(qualitative_vars))))
```
```{r}
#library(leaps)
#regfit.full=regsubsets(crim~.,data=Boston, nvmax=13) ## default is 8
#reg.summary=summary(regfit.full)
#names(reg.summary)

#- Exclude useless columns by correlation above or PCA
#library(parameters)
#m_stepwise <- lm(Price ~., df %>% select(-X, -ID, -Name))
#m_stepwise <- select_parameters(m_stepwise)
#  
#summary(m_stepwise)
#```
#```{r}
## PCA
#quantitative_vars_pca = c("Host.Since","Host.Response.Rate","Price","Security.Deposit","Cleaning.Fee","Number.of.Reviews","Review.Scores.Rating","dist#_from_city_center")
#df_pca <- scale(df %>% filter(City== 'Amsterdam') %>% dplyr::select(all_of(quantitative_vars_pca)) %>% select(-Price))
#pca <- FactoMineR::PCA(df_pca, graph=TRUE)
#fviz_screeplot(pca, addlabels=TRUE )
#pca_res = prcomp(df_pca)
#autoplot(pca_res)
#```
#```{r, fig.height=4}
##- try clustering by city and clustering the entire dataset to show if changes
#
#
##fviz_screeplot(pca, addlabels=TRUE )
##fviz_pca_var(pca, col.var ="contrib", gradient.cols = c("pink", "violet", "blue"),
##             repel=TRUE)
#c1 = fviz_contrib(pca, choice='var', axes=1, top=10)
#c2 = fviz_contrib(pca, choice='var', axes=2, top=10)
#c3 = fviz_contrib(pca, choice='var', axes=3, top=10)
#c4 = fviz_contrib(pca, choice='var', axes=4, top=10)
#grid.arrange(c1, c2, c3, c4,  nrow = 2)
#```
#```{r}
#fviz_screeplot(pca, addlabels=TRUE )
##fviz_pca_var(pca, col.var ="contrib", gradient.cols = c("pink", "violet", "blue"),
##             repel=TRUE)
#```
#```{r}
#fviz_pca_var(pca, col.var ="contrib", gradient.cols = c("green", "brown", "blue"), repel=TRUE)
#```
#```{r}
#library(ggplot2)
#library(ggfortify)
#pca_res = prcomp(df_pca)
#autoplot(pca_res)
#```
#```{r}
#k.means.fit = kmeans(df_pca, 3) # k = 3
#
#wssplot <- function(df, nc=15, seed=1234){
#  wss <- (nrow(dati)-1)*sum(apply(df,2,var))
#  for (i in 2:nc){
#    set.seed(seed)
#    wss[i] <- sum(kmeans(df, centers=i)$withinss)}
#  plot(1:nc, wss, type="b", xlab="Number of Clusters",
#       ylab="Within groups sum of squares")}
#
#wssplot(dati.stand, nc=3)
#summary(dati[k.means.fit$cluster==1,"women_parl"])
#summary(dati[k.means.fit$cluster==2,"women_parl"])
#summary(dati[k.means.fit$cluster==3,"women_parl"])
#
#boxplot(dati$women_parl ~ k.means.fit$cluster)
#
#library(cluster)
#tmp_df = df %>% dplyr::select(all_of(quantitative_vars))%>% sample_n(1000)
#k.means.fit = kmeans(df_pca, 2) # k = 3
#clusplot(df_pca, k.means.fit$cluster, main='Cluster representation', color=TRUE, shade=TRUE, labels=2, lines=0)
#
#```
#```{r}
#library(cluster)
#tmp_df = df %>% sample_n(1000) 
#d <- cluster::daisy(tmp_df %>% select (-X, -ID, -Name, -City, -Latitude, -Longitude), metric = "gower") # Euclidean distance matrix.
#H.fit <- hclust(d, method="ward.D2")
#plot(H.fit) # display dendogram
#groups <- cutree(H.fit, k=3) # cut tree into 3 clusters
## draw dendogram with red borders around the 3 clusters
#rect.hclust(H.fit, k=3, border="red")
#
#map_df = tmp_df
#map_df$label = groups
#
#pal <- colorNumeric(
#  palette = "viridis",
#  domain = map_df$label)
#
#
#tmp_map <-leaflet(map_df) %>% addProviderTiles('CartoDB.Positron') %>% 
#addCircleMarkers(lng= ~Longitude, lat= ~Latitude, color= ~pal(label), radius=1, label =  ~label) %>%
#addLegend(pal = pal, values = ~label, title = "Average price",
#labFormat = labelFormat())
#  tmp_map
#  
#map_df$label = factor(map_df$label)
#plot_ly(map_df, y = ~Host.Since, color = ~label, type = "box")
#plot_ly(map_df, y = ~Accommodates, color = ~label, type = "box")
#plot_ly(map_df, y = ~Security.Deposit, color = ~label, type = "box")
#plot_ly(map_df, y = ~Review.Scores.Rating, color = ~label, type = "box")
#plot_ly(map_df, y = ~Review.Scores.Rating, color = ~label, type = "box")
#plot_ly(map_df, y = ~Review.Scores.Rating, color = ~label, type = "box")
#```
#```{r}
#clusterdata.mean<-function(data,groups){
#  aggregate(data,list(groups),function(x)mean(as.numeric(x)))
#}
#
#clusterdata.mean(map_df,map_df$label)
#-# try and predict a price of something
#```
#```{r}
#- evaluate model
#```
#```{r}
#- Try and predict the city of a room based on other charateristics
#```
#```{r}
#- try clusters with and w/out prices and see if prices variance is small in the clusters
#```
#```{r}
#- Try and predict the review scores
#
#
#```
#sub selection
#linear model
#Residui normali
#logit
#knn su bin della continuous var 
#cluster
#finals

